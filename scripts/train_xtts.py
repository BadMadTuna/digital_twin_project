import os
import torch
from trainer import Trainer, TrainerArgs
from TTS.tts.configs.shared_configs import BaseDatasetConfig
from TTS.tts.configs.xtts_config import XttsConfig, XttsArgs
from TTS.tts.datasets import load_tts_samples
from TTS.tts.models.xtts import Xtts
from TTS.utils.manage import ModelManager

# === CONFIGURATION ===
PROJECT_ROOT = os.getcwd()
DATASET_PATH = os.path.join(PROJECT_ROOT, "audio_data/dataset")
OUTPUT_PATH = os.path.join(PROJECT_ROOT, "models/xtts_finetuned")
METADATA_FILE = "metadata.csv"
LANGUAGE = "en"
# =====================

# Agree to license
os.environ["COQUI_TOS_AGREED"] = "1"

def custom_formatter(root_path, manifest_file, **kwargs):
    """
    Adapts your VITS metadata format (wav|text) to XTTS format (wav|text|speaker|lang)
    """
    items = []
    manifest_path = os.path.join(root_path, manifest_file)
    
    with open(manifest_path, "r", encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split("|")
            if len(parts) < 2: continue
            
            wav_file = parts[0].strip()
            text = "|".join(parts[1:]).strip()
            
            # Find the full path
            wav_path = os.path.join(root_path, wav_file)
            if not os.path.exists(wav_path):
                 wav_path = os.path.join(root_path, "wavs", wav_file)

            if os.path.exists(wav_path):
                items.append({
                    "text": text,
                    "audio_file": wav_path,
                    "speaker_name": "my_voice",  # XTTS needs a speaker ID
                    "language": LANGUAGE
                })
    return items

def train_xtts():
    # 1. Dataset Config
    dataset_config = BaseDatasetConfig(
        formatter="custom_formatter",
        meta_file_train=METADATA_FILE,
        path=DATASET_PATH,
        language=LANGUAGE
    )

    # 2. XTTS Configuration
    config = XttsConfig(
        batch_size=8,   # XTTS is heavy, keep batch size low (4-8)
        eval_batch_size=2,
        num_loader_workers=2,
        num_eval_loader_workers=1,
        run_eval=True,
        test_delay_epochs=-1,
        epochs=15,      # <--- XTTS converges VERY fast. 15 is usually enough.
        text_cleaner="whitespace_cleaner",
        use_phonemes=False, # XTTS uses GPT-2 BPE, not phonemes
        #language=LANGUAGE,
        print_step=50,
        print_eval=True,
        save_step=500,
        output_path=OUTPUT_PATH,
        datasets=[dataset_config],
    )

    # 3. Load Model
    print("â¬‡ï¸  Loading XTTS v2 Base...")
    model = Xtts.init_from_config(config)
    
    # FIX: Manually define paths since manager.download_model is returning None
    # Based on your logs, the model is located here:
    checkpoint_dir = os.path.expanduser("~/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2")
    
    model_path = os.path.join(checkpoint_dir, "model.pth")
    vocab_path = os.path.join(checkpoint_dir, "vocab.json")
    speaker_path = os.path.join(checkpoint_dir, "speakers_xtts.pth")

    # Check if files exist to avoid vague errors
    if not os.path.exists(model_path):
        print(f"âŒ Error: Model not found at {model_path}")
        return

    print(f"ðŸ“‚ Loading Checkpoint from: {checkpoint_dir}")
    
    # Load with explicit paths
    model.load_checkpoint(
        config, 
        checkpoint_path=model_path, 
        vocab_path=vocab_path, 
        speaker_file_path=speaker_path,  # Explicitly pass this to prevent the crash
        eval=True
    )

    # 4. Load Data
    print("ðŸ“‚ Loading Data...")
    train_samples, eval_samples = load_tts_samples(
        dataset_config,
        eval_split=True,
        eval_split_size=0.1,
        formatter=custom_formatter
    )

    # 5. Trainer
    trainer = Trainer(
        TrainerArgs(),
        config,
        output_path=OUTPUT_PATH,
        model=model,
        train_samples=train_samples,
        eval_samples=eval_samples,
    )

    print("ðŸš€ Starting XTTS Fine-Tuning...")
    trainer.fit()

if __name__ == "__main__":
    train_xtts()